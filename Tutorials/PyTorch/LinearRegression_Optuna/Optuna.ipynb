{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42387fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d899c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 10:12:02,131]\u001b[0m A new study created in memory with name: no-name-caeec899-7dfe-4997-97e3-dec27f482aae\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 10:12:02,184]\u001b[0m Trial 0 finished with value: 0.17533503684381302 and parameters: {'x': 2.418730267408284}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,186]\u001b[0m Trial 1 finished with value: 35.771761269064434 and parameters: {'x': -3.9809498634468117}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,187]\u001b[0m Trial 2 finished with value: 86.72582220732045 and parameters: {'x': -7.312669982734299}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,188]\u001b[0m Trial 3 finished with value: 4.507561744891354 and parameters: {'x': 4.123101915804174}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,189]\u001b[0m Trial 4 finished with value: 22.759933015279245 and parameters: {'x': -2.7707371563815215}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,190]\u001b[0m Trial 5 finished with value: 20.47795807825745 and parameters: {'x': -2.525257791359234}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,191]\u001b[0m Trial 6 finished with value: 11.704134804783534 and parameters: {'x': -1.4211306325224609}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,192]\u001b[0m Trial 7 finished with value: 0.5598669852425378 and parameters: {'x': 1.2517574021465112}. Best is trial 0 with value: 0.17533503684381302.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,192]\u001b[0m Trial 8 finished with value: 0.07371006977926904 and parameters: {'x': 1.7285040151691575}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,193]\u001b[0m Trial 9 finished with value: 63.58196711732193 and parameters: {'x': -5.973830140987575}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,213]\u001b[0m Trial 10 finished with value: 57.82614499683316 and parameters: {'x': 9.604350399398568}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,217]\u001b[0m Trial 11 finished with value: 4.369199473459396 and parameters: {'x': 4.090263015378542}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,220]\u001b[0m Trial 12 finished with value: 0.811509003602183 and parameters: {'x': 2.9008379452499673}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,224]\u001b[0m Trial 13 finished with value: 25.51958069052273 and parameters: {'x': 7.051690874402622}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,226]\u001b[0m Trial 14 finished with value: 141.69319927956494 and parameters: {'x': -9.903495254737784}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,229]\u001b[0m Trial 15 finished with value: 1.0991741337499412 and parameters: {'x': 0.9515849420434952}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,232]\u001b[0m Trial 16 finished with value: 23.74558437835597 and parameters: {'x': 6.87294411812366}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,236]\u001b[0m Trial 17 finished with value: 4.510180274514582 and parameters: {'x': -0.12371850171216936}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,238]\u001b[0m Trial 18 finished with value: 12.066647975259546 and parameters: {'x': 5.473708101619874}. Best is trial 8 with value: 0.07371006977926904.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,240]\u001b[0m Trial 19 finished with value: 0.057464493852607317 and parameters: {'x': 2.2397175292977285}. Best is trial 19 with value: 0.057464493852607317.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,243]\u001b[0m Trial 20 finished with value: 57.526490907597534 and parameters: {'x': 9.584622001629187}. Best is trial 19 with value: 0.057464493852607317.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,246]\u001b[0m Trial 21 finished with value: 0.6362614273345553 and parameters: {'x': 2.7976599697456024}. Best is trial 19 with value: 0.057464493852607317.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,248]\u001b[0m Trial 22 finished with value: 4.476051258461423 and parameters: {'x': -0.1156680407052102}. Best is trial 19 with value: 0.057464493852607317.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,251]\u001b[0m Trial 23 finished with value: 0.05324052379978257 and parameters: {'x': 2.2307390816480437}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,255]\u001b[0m Trial 24 finished with value: 10.850353891847355 and parameters: {'x': 5.293987536686706}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,257]\u001b[0m Trial 25 finished with value: 11.021369130979465 and parameters: {'x': -1.3198447450113482}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,260]\u001b[0m Trial 26 finished with value: 0.33970400662340516 and parameters: {'x': 1.4171586780062646}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,263]\u001b[0m Trial 27 finished with value: 23.946051197831398 and parameters: {'x': 6.893470261259528}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,266]\u001b[0m Trial 28 finished with value: 4.54458881585513 and parameters: {'x': 4.131804122299966}. Best is trial 23 with value: 0.05324052379978257.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,269]\u001b[0m Trial 29 finished with value: 0.01711347758716011 and parameters: {'x': 2.1308184909986356}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,273]\u001b[0m Trial 30 finished with value: 0.6746889610585981 and parameters: {'x': 2.8213945221746966}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,277]\u001b[0m Trial 31 finished with value: 0.16258977916505432 and parameters: {'x': 1.5967757706126102}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,279]\u001b[0m Trial 32 finished with value: 4.54987323221763 and parameters: {'x': -0.13304318573666718}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,282]\u001b[0m Trial 33 finished with value: 9.794036417293905 and parameters: {'x': 5.129542525241334}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,287]\u001b[0m Trial 34 finished with value: 44.29942246973651 and parameters: {'x': -4.655781131447797}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,290]\u001b[0m Trial 35 finished with value: 0.06556857131876219 and parameters: {'x': 2.2560636079546685}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,293]\u001b[0m Trial 36 finished with value: 1.882068741825147 and parameters: {'x': 3.371885105183793}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,296]\u001b[0m Trial 37 finished with value: 11.089566493880548 and parameters: {'x': -1.3301000726525545}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,298]\u001b[0m Trial 38 finished with value: 25.437449776068856 and parameters: {'x': -3.043555271439866}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,302]\u001b[0m Trial 39 finished with value: 2.209134135538815 and parameters: {'x': 0.5136843755316252}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,305]\u001b[0m Trial 40 finished with value: 0.07173112836386705 and parameters: {'x': 2.2678266759750922}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,308]\u001b[0m Trial 41 finished with value: 0.07212494702233667 and parameters: {'x': 2.268560881407432}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,312]\u001b[0m Trial 42 finished with value: 3.5449766850300914 and parameters: {'x': 3.8828108468537383}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,315]\u001b[0m Trial 43 finished with value: 0.12797590250374574 and parameters: {'x': 2.357737197539962}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,320]\u001b[0m Trial 44 finished with value: 7.6386396056971435 and parameters: {'x': 4.763808894568715}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,324]\u001b[0m Trial 45 finished with value: 8.12796665563002 and parameters: {'x': -0.8509589010769729}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,327]\u001b[0m Trial 46 finished with value: 18.207946925999448 and parameters: {'x': -2.2670770939835916}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,330]\u001b[0m Trial 47 finished with value: 16.125314838721376 and parameters: {'x': 6.015633802866165}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,336]\u001b[0m Trial 48 finished with value: 1.8794433046960328 and parameters: {'x': 0.6290721008397149}. Best is trial 29 with value: 0.01711347758716011.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,340]\u001b[0m Trial 49 finished with value: 0.009901666013140985 and parameters: {'x': 2.0995071153895086}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,343]\u001b[0m Trial 50 finished with value: 0.12622489922688043 and parameters: {'x': 1.6447185633516994}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,347]\u001b[0m Trial 51 finished with value: 2.395651769890532 and parameters: {'x': 3.5477893170230024}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,350]\u001b[0m Trial 52 finished with value: 0.06489024352144455 and parameters: {'x': 2.254735634573266}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,354]\u001b[0m Trial 53 finished with value: 0.8869830771756342 and parameters: {'x': 1.0582022100388884}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,358]\u001b[0m Trial 54 finished with value: 6.933284199969632 and parameters: {'x': 4.633113024533818}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,360]\u001b[0m Trial 55 finished with value: 1.3954648794207756 and parameters: {'x': 3.1812979638604206}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,363]\u001b[0m Trial 56 finished with value: 2.7557690852779926 and parameters: {'x': 0.339949071480639}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,365]\u001b[0m Trial 57 finished with value: 16.655917619831413 and parameters: {'x': 6.081166208307549}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,370]\u001b[0m Trial 58 finished with value: 0.09249850326711524 and parameters: {'x': 2.304135665891252}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,373]\u001b[0m Trial 59 finished with value: 38.48424359626875 and parameters: {'x': 8.20356700586596}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,376]\u001b[0m Trial 60 finished with value: 5.853742293988461 and parameters: {'x': -0.4194508248750295}. Best is trial 49 with value: 0.009901666013140985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,379]\u001b[0m Trial 61 finished with value: 0.007285415903554382 and parameters: {'x': 2.0853546478146}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,381]\u001b[0m Trial 62 finished with value: 0.008729206041158509 and parameters: {'x': 1.9065697798292303}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,385]\u001b[0m Trial 63 finished with value: 0.5764926952045946 and parameters: {'x': 1.240728839475254}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,388]\u001b[0m Trial 64 finished with value: 0.03202624189939994 and parameters: {'x': 1.8210412284927058}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,391]\u001b[0m Trial 65 finished with value: 5.849336028341676 and parameters: {'x': 4.418540061347274}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,395]\u001b[0m Trial 66 finished with value: 1.184675142107398 and parameters: {'x': 3.088427830454274}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,398]\u001b[0m Trial 67 finished with value: 2.776742572510642 and parameters: {'x': 3.6663560761465845}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,401]\u001b[0m Trial 68 finished with value: 0.0561246186715514 and parameters: {'x': 1.7630936499974064}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,405]\u001b[0m Trial 69 finished with value: 0.04638036987803679 and parameters: {'x': 1.78463897781159}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,408]\u001b[0m Trial 70 finished with value: 7.178451170790585 and parameters: {'x': -0.679263176843698}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,411]\u001b[0m Trial 71 finished with value: 0.026536215935557363 and parameters: {'x': 1.837100595656223}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,414]\u001b[0m Trial 72 finished with value: 1.3847077624369706 and parameters: {'x': 0.8232639367993472}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,420]\u001b[0m Trial 73 finished with value: 0.1820927064383876 and parameters: {'x': 1.5732767800571574}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,423]\u001b[0m Trial 74 finished with value: 3.0928751335016567 and parameters: {'x': 0.2413428038694816}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,427]\u001b[0m Trial 75 finished with value: 118.30072137030453 and parameters: {'x': -8.876613506524194}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,429]\u001b[0m Trial 76 finished with value: 0.6076631110011157 and parameters: {'x': 2.779527492139383}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,433]\u001b[0m Trial 77 finished with value: 0.9122483584181077 and parameters: {'x': 1.0448830655788226}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,444]\u001b[0m Trial 78 finished with value: 15.516015816044602 and parameters: {'x': -1.9390374225240108}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,448]\u001b[0m Trial 79 finished with value: 0.05907693393119366 and parameters: {'x': 1.7569425295713097}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,455]\u001b[0m Trial 80 finished with value: 0.7850063343292488 and parameters: {'x': 2.8860058319950546}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,460]\u001b[0m Trial 81 finished with value: 0.015468436626703802 and parameters: {'x': 1.875627830176105}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,467]\u001b[0m Trial 82 finished with value: 4.685954934810906 and parameters: {'x': 4.16470666253211}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,473]\u001b[0m Trial 83 finished with value: 0.0493157470473829 and parameters: {'x': 1.7779285091521586}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,476]\u001b[0m Trial 84 finished with value: 4.094995650283797 and parameters: {'x': -0.02360955974313317}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,479]\u001b[0m Trial 85 finished with value: 0.020524439657014455 and parameters: {'x': 1.856736467804907}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,486]\u001b[0m Trial 86 finished with value: 1.7806090471944123 and parameters: {'x': 0.6656053630224632}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,493]\u001b[0m Trial 87 finished with value: 0.4793054313401498 and parameters: {'x': 2.6923188798091164}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,496]\u001b[0m Trial 88 finished with value: 2.317518023221785 and parameters: {'x': 3.5223396543550276}. Best is trial 61 with value: 0.007285415903554382.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,499]\u001b[0m Trial 89 finished with value: 0.00580154995252759 and parameters: {'x': 1.9238320936842321}. Best is trial 89 with value: 0.00580154995252759.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,502]\u001b[0m Trial 90 finished with value: 0.685341676975008 and parameters: {'x': 1.17214634326168}. Best is trial 89 with value: 0.00580154995252759.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,506]\u001b[0m Trial 91 finished with value: 0.4335998616183321 and parameters: {'x': 2.658483000250069}. Best is trial 89 with value: 0.00580154995252759.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,508]\u001b[0m Trial 92 finished with value: 0.0010355942708609178 and parameters: {'x': 2.032180650566154}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,511]\u001b[0m Trial 93 finished with value: 1.246920340221414 and parameters: {'x': 3.1166558736788224}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,514]\u001b[0m Trial 94 finished with value: 0.40379533308145465 and parameters: {'x': 1.3645510775196368}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,517]\u001b[0m Trial 95 finished with value: 0.0017608652488128687 and parameters: {'x': 1.9580373350606415}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,520]\u001b[0m Trial 96 finished with value: 3.4558575988286124 and parameters: {'x': 3.858993705967993}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,524]\u001b[0m Trial 97 finished with value: 2.659937001941638 and parameters: {'x': 0.36906867037829016}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,527]\u001b[0m Trial 98 finished with value: 0.024344808986917994 and parameters: {'x': 2.156028231377908}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 10:12:02,529]\u001b[0m Trial 99 finished with value: 1.7308423928439056 and parameters: {'x': 3.315614834533233}. Best is trial 92 with value: 0.0010355942708609178.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 2.032180650566154}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials = 100)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64636b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6374bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8bbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int('n_units_l{}'.format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float('dropout_l{}'.format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7e190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(\n",
    "            root = 'data',\n",
    "            train = True,\n",
    "            download = True,\n",
    "            transform = transforms.ToTensor()\n",
    "        ),\n",
    "        batch_size = BATCHSIZE,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(\n",
    "            root = 'data',\n",
    "            train = False,\n",
    "            download = True,\n",
    "            transform = transforms.ToTensor()\n",
    "        ),\n",
    "        batch_size = BATCHSIZE,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f725df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log = True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr = lr)\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "            \n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "\n",
    "                pred = output.argmax(dim = 1, keepdim = True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b7dee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 11:20:35,954]\u001b[0m A new study created in memory with name: no-name-1963ccf5-03c7-41df-8bf6-7daae3463a4c\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:40,306]\u001b[0m Trial 0 finished with value: 0.1515625 and parameters: {'n_layers': 3, 'n_units_l0': 43, 'dropout_l0': 0.4454749279030757, 'n_units_l1': 81, 'dropout_l1': 0.2562585942059985, 'n_units_l2': 99, 'dropout_l2': 0.4183903908296933, 'optimizer': 'SGD', 'lr': 0.005460329367164179}. Best is trial 0 with value: 0.1515625.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:43,619]\u001b[0m Trial 1 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_l0': 41, 'dropout_l0': 0.413346167836529, 'optimizer': 'Adam', 'lr': 0.001949680512977771}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:47,170]\u001b[0m Trial 2 finished with value: 0.1078125 and parameters: {'n_layers': 3, 'n_units_l0': 69, 'dropout_l0': 0.4202576066417447, 'n_units_l1': 22, 'dropout_l1': 0.2820404630588114, 'n_units_l2': 26, 'dropout_l2': 0.31773433173792015, 'optimizer': 'Adam', 'lr': 0.054885806941193674}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:50,624]\u001b[0m Trial 3 finished with value: 0.6078125 and parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.34377575809936467, 'n_units_l1': 67, 'dropout_l1': 0.36927639206732366, 'optimizer': 'Adam', 'lr': 0.05603679389949849}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:54,248]\u001b[0m Trial 4 finished with value: 0.70390625 and parameters: {'n_layers': 3, 'n_units_l0': 124, 'dropout_l0': 0.48029962990324815, 'n_units_l1': 100, 'dropout_l1': 0.4223232547414516, 'n_units_l2': 40, 'dropout_l2': 0.23470172803556993, 'optimizer': 'RMSprop', 'lr': 0.0002720056029932746}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:57,409]\u001b[0m Trial 5 finished with value: 0.77890625 and parameters: {'n_layers': 2, 'n_units_l0': 40, 'dropout_l0': 0.20813545468808373, 'n_units_l1': 32, 'dropout_l1': 0.24355078673741848, 'optimizer': 'RMSprop', 'lr': 0.0005982326047592392}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:57,752]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:20:58,391]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:01,825]\u001b[0m Trial 8 finished with value: 0.80234375 and parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.44976483408719314, 'optimizer': 'Adam', 'lr': 0.002998847190660288}. Best is trial 1 with value: 0.81328125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:02,279]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:02,800]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:06,355]\u001b[0m Trial 11 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 64, 'dropout_l0': 0.4997279650766082, 'optimizer': 'Adam', 'lr': 0.00444903749784504}. Best is trial 11 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:10,180]\u001b[0m Trial 12 finished with value: 0.80703125 and parameters: {'n_layers': 1, 'n_units_l0': 55, 'dropout_l0': 0.4913615637118145, 'optimizer': 'Adam', 'lr': 0.009293994221736315}. Best is trial 11 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:10,606]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:14,630]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:15,076]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:16,010]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:22,019]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:27,112]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:30,650]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:32,575]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:38,337]\u001b[0m Trial 21 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.49867806994143044, 'optimizer': 'Adam', 'lr': 0.00929529689904463}. Best is trial 21 with value: 0.8203125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:42,637]\u001b[0m Trial 22 finished with value: 0.8 and parameters: {'n_layers': 1, 'n_units_l0': 63, 'dropout_l0': 0.49964972806293056, 'optimizer': 'Adam', 'lr': 0.008602855370927295}. Best is trial 21 with value: 0.8203125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:43,177]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:43,588]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:44,138]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:44,649]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:45,245]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:45,693]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:46,242]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:46,727]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:47,302]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:47,770]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:52,283]\u001b[0m Trial 33 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.4538581917906663, 'optimizer': 'Adam', 'lr': 0.006113042541051644}. Best is trial 33 with value: 0.8234375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:53,482]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:57,550]\u001b[0m Trial 35 finished with value: 0.80859375 and parameters: {'n_layers': 2, 'n_units_l0': 102, 'dropout_l0': 0.41182829392838793, 'n_units_l1': 101, 'dropout_l1': 0.3123523912380295, 'optimizer': 'Adam', 'lr': 0.00576603983414206}. Best is trial 33 with value: 0.8234375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:57,983]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:59,082]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:59,476]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:21:59,890]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:00,293]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:00,718]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:01,164]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:01,584]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:05,273]\u001b[0m Trial 44 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.3803961515249488, 'optimizer': 'Adam', 'lr': 0.007757235287845501}. Best is trial 33 with value: 0.8234375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:05,812]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:06,419]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:06,921]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:07,352]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:10,628]\u001b[0m Trial 49 finished with value: 0.825 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_l0': 0.3510031459355515, 'optimizer': 'Adam', 'lr': 0.0090676832862761}. Best is trial 49 with value: 0.825.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:13,829]\u001b[0m Trial 50 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 59, 'dropout_l0': 0.2752998351210632, 'optimizer': 'Adam', 'lr': 0.007250285080953145}. Best is trial 49 with value: 0.825.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:17,075]\u001b[0m Trial 51 finished with value: 0.7984375 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_l0': 0.3516241367203146, 'optimizer': 'Adam', 'lr': 0.009115056290610116}. Best is trial 49 with value: 0.825.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:17,427]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:17,818]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:18,184]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:18,538]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:19,262]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:19,625]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:20,000]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:20,404]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:21,439]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:21,814]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:25,355]\u001b[0m Trial 62 finished with value: 0.834375 and parameters: {'n_layers': 1, 'n_units_l0': 59, 'dropout_l0': 0.2790234971149452, 'optimizer': 'Adam', 'lr': 0.007362134844235783}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:28,624]\u001b[0m Trial 63 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 54, 'dropout_l0': 0.24080876290141423, 'optimizer': 'Adam', 'lr': 0.011543530787502152}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:29,625]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:32,893]\u001b[0m Trial 65 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 51, 'dropout_l0': 0.20532821400237228, 'optimizer': 'Adam', 'lr': 0.011343165162498652}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:33,260]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:33,989]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:35,336]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:35,706]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:38,963]\u001b[0m Trial 70 finished with value: 0.79296875 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.2844890884983403, 'optimizer': 'Adam', 'lr': 0.011310195498492093}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:40,580]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:42,214]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:42,581]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:45,761]\u001b[0m Trial 74 finished with value: 0.80625 and parameters: {'n_layers': 1, 'n_units_l0': 48, 'dropout_l0': 0.20647638385330858, 'optimizer': 'Adam', 'lr': 0.005657433026646062}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:46,758]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:47,115]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:47,506]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:47,880]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:51,109]\u001b[0m Trial 79 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 69, 'dropout_l0': 0.32091727663858577, 'optimizer': 'Adam', 'lr': 0.007784677756044669}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:54,461]\u001b[0m Trial 80 finished with value: 0.825 and parameters: {'n_layers': 1, 'n_units_l0': 81, 'dropout_l0': 0.31313245599251144, 'optimizer': 'Adam', 'lr': 0.005258538275915199}. Best is trial 62 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:54,842]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:56,509]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:22:56,880]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:00,152]\u001b[0m Trial 84 finished with value: 0.83828125 and parameters: {'n_layers': 1, 'n_units_l0': 65, 'dropout_l0': 0.29307177019081093, 'optimizer': 'Adam', 'lr': 0.008357774963595297}. Best is trial 84 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:00,505]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:03,745]\u001b[0m Trial 86 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'dropout_l0': 0.31715214966334493, 'optimizer': 'Adam', 'lr': 0.008960985233317361}. Best is trial 84 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:04,114]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:04,808]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:05,176]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:05,531]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:08,929]\u001b[0m Trial 91 finished with value: 0.8140625 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.33804122649427415, 'optimizer': 'Adam', 'lr': 0.014147267845581442}. Best is trial 84 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:12,701]\u001b[0m Trial 92 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_l0': 65, 'dropout_l0': 0.3587638756393953, 'optimizer': 'Adam', 'lr': 0.009976297477212313}. Best is trial 92 with value: 0.8390625.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:13,184]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:13,624]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:14,405]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:14,835]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:15,277]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:15,776]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-29 11:23:16,437]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  72\n",
      "  Number of completed trials:  28\n",
      "Best trials:\n",
      "  Value:  0.8390625\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 65\n",
      "    dropout_l0: 0.3587638756393953\n",
      "    optimizer: Adam\n",
      "    lr: 0.009976297477212313\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 100, timeout = 600)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of completed trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trials:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0b596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "21cm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
